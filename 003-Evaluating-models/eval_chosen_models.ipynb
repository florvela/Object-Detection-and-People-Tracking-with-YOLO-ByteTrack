{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSjXQ8eB2D6s",
    "outputId": "3745517f-4e04-4661-8d7e-27112d318abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_yolov8_tf_yolov8l_imgsz_640_epochs_50_batch_16_dataset_v2_loss_SGD_lr_01\r\n",
      "model_yolov8_tf_yolov8m_imgsz_640_epochs_100_batch_16_dataset_v2_loss_SGD_lr_01\r\n",
      "model_yolov8_tf_yolov8m_imgsz_640_epochs_50_batch_16_dataset_v2_loss_SGD_lr_01\r\n",
      "model_yolov8_tf_yolov8s_imgsz_800_epochs_100_batch_16_dataset_v2_loss_SGD_lr_01\r\n",
      "model_yolov8_tf_yolov8s_imgsz_800_epochs_60_batch_16_dataset_v2_loss_SGD_lr_01\r\n"
     ]
    }
   ],
   "source": [
    "train_results_dir = os.getcwd() + \"/../002-Training-models/train_results/chosen_models\"\n",
    "!ls {train_results_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_dir = os.getcwd()\n",
    "dataset_dir = os.getcwd()+\"/../datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(train_results_dir, output_file, dataset_dir, task=\"val\", dataset_sufix=\"_original\", dataset_version=\"v1\"):\n",
    "    %cd {eval_results_dir}\n",
    "    total = len(os.listdir(train_results_dir))\n",
    "    counter = 0\n",
    "    for folder_name in sorted(os.listdir(train_results_dir)):\n",
    "        counter += 1\n",
    "        if not folder_name.startswith(\"model\"):\n",
    "            continue\n",
    "\n",
    "        folder_path = os.path.join(train_results_dir, folder_name, \"weights\")\n",
    "        print(f\"Evaluatig models on {task}: {counter}/{total}\")\n",
    "\n",
    "        # Split the folder name into variables\n",
    "        variables = folder_name.split('_')\n",
    "\n",
    "        # Extract the required variables\n",
    "        model = variables[1]\n",
    "        tf = variables[3]\n",
    "        imgsz = variables[5]\n",
    "        epochs = variables[7]\n",
    "        batch = variables[9]\n",
    "        dataset = variables[11]\n",
    "        loss = variables[13]\n",
    "        lr = variables[15]\n",
    "\n",
    "        print(folder_name)\n",
    "        print(\"Model:\", model)\n",
    "        print(\"TF:\", tf)\n",
    "        print(\"Imgsz:\", imgsz)\n",
    "        print(\"Epochs:\", epochs)\n",
    "        print(\"Batch:\", batch)\n",
    "        print(\"Dataset:\", dataset)\n",
    "        print(\"Executing command...\")\n",
    "        print()\n",
    "\n",
    "        dataset_location = dataset_dir + model + dataset_sufix\n",
    "\n",
    "        command = None\n",
    "\n",
    "        if model == \"yolov8\" and dataset == dataset_version:\n",
    "            best_pt_path = os.path.join(folder_path, \"best.pt\")\n",
    "            if os.path.exists(best_pt_path):\n",
    "                %cd yolov8\n",
    "                command = f\"yolo val model={best_pt_path} data={dataset_location}/data.yaml split={task} name={folder_name}\"\n",
    "                print(command)\n",
    "\n",
    "        if command:\n",
    "            # Run the command using subprocess.Popen and capture the output\n",
    "            with subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True) as process:\n",
    "                # Open the output file for writing\n",
    "                with open(f\"{eval_results_dir}/{output_file}\", \"a\") as file:\n",
    "                    file.write(folder_name)\n",
    "                    file.write(f\"\\nModel: {model}\")\n",
    "                    file.write(f\"\\nTF: {tf}\")\n",
    "                    file.write(f\"\\nImgsz: {imgsz}\")\n",
    "                    file.write(f\"\\nEpochs: {epochs}\")\n",
    "                    file.write(f\"\\nBatch: {batch}\")\n",
    "                    file.write(f\"\\nDataset: {dataset}\")\n",
    "                    file.write(f\"\\nLoss: {loss}\")\n",
    "                    file.write(f\"\\nLr0: {lr}\\n\")\n",
    "                    # Read and display each line of the output as it becomes available\n",
    "                    for line in process.stdout:\n",
    "                        print(line, end=\"\")\n",
    "                        file.write(line)\n",
    "            %cd ..\n",
    "\n",
    "        from IPython import display\n",
    "        display.clear_output()\n",
    "\n",
    "\n",
    "    print(\"Executing commands...\", \"DONE!\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path, csv_output_file):\n",
    "    results = list()\n",
    "    curr_res = dict()\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"Model:\"):\n",
    "            curr_res[\"model\"] = line.split()[1]\n",
    "        elif line.startswith(\"TF:\"):\n",
    "            curr_res[\"transfer_learning\"] = line.split()[1]\n",
    "        elif line.startswith(\"Imgsz:\"):\n",
    "            curr_res[\"imgsz\"] = line.split()[1]\n",
    "        elif line.startswith(\"Epochs:\"):\n",
    "            curr_res[\"epochs\"] = line.split()[1]\n",
    "        elif line.startswith(\"Batch:\"):\n",
    "            curr_res[\"batch\"] = line.split()[1]\n",
    "        elif line.startswith(\"Dataset:\"):\n",
    "            curr_res[\"dataset\"] = line.split()[1]\n",
    "        elif line.startswith(\"Loss:\"):\n",
    "            curr_res[\"optimizer\"] = line.split()[1]\n",
    "        elif line.startswith(\"Lr0:\"):\n",
    "            try:\n",
    "                curr_res[\"lr0\"] = float(\"0.\"+line.split()[1])\n",
    "            except:\n",
    "                curr_res[\"lr0\"] = float(line.split()[1])\n",
    "            \n",
    "        if line.strip(\" \").startswith(\"all\"):\n",
    "            P, R, mAP5, mAP95 = line.split()[3:]\n",
    "            curr_res[\"all_P\"] = P\n",
    "            curr_res[\"all_R\"] = R\n",
    "            curr_res[\"all_F1\"] = (float(P) * float(R)) / (float(P) + float(R))\n",
    "            curr_res[\"all_mAP@.5\"] = mAP5\n",
    "            curr_res[\"all_mAP@.5:.95\"] = mAP95\n",
    "\n",
    "        elif line.strip(\" \").startswith(\"knife\"):\n",
    "            P, R, mAP5, mAP95 = line.split()[3:]\n",
    "            curr_res[\"knife_P\"] = P\n",
    "            curr_res[\"knife_R\"] = R\n",
    "            curr_res[\"knife_F1\"] = (float(P) * float(R)) / (float(P) + float(R))\n",
    "            curr_res[\"knife_mAP@.5\"] = mAP5\n",
    "            curr_res[\"knife_mAP@.5:.95\"] = mAP95\n",
    "\n",
    "        elif line.strip(\" \").startswith(\"pistol\") or line.strip(\" \").startswith(\"gun\"):\n",
    "            P, R, mAP5, mAP95 = line.split()[3:]\n",
    "            curr_res[\"pistol_P\"] = P\n",
    "            curr_res[\"pistol_R\"] = R\n",
    "            curr_res[\"pistol_F1\"] = (float(P) * float(R)) / (float(P) + float(R))\n",
    "            curr_res[\"pistol_mAP@.5\"] = mAP5\n",
    "            curr_res[\"pistol_mAP@.5:.95\"] = mAP95\n",
    "        \n",
    "        elif line.strip(\" \").startswith(\"Speed:\"):\n",
    "            ms = 0\n",
    "            for i in [1,3,5,7]:\n",
    "                ms += float(line.replace(\"ms\",\"\").split(\" \")[i])\n",
    "            curr_res[\"FPS\"] = 1000/ms\n",
    "\n",
    "        elif line.strip(\" \").startswith(\"Results saved to\"):\n",
    "            model_key = line.split(\"/\")[-1].replace('\\x1b[0m', '').replace('\\n', '')\n",
    "            model_info = model_key.split(\"_\")\n",
    "\n",
    "            curr_res[\"model_key\"] = model_key\n",
    "\n",
    "            results.append(curr_res)\n",
    "            curr_res = dict()\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.set_index('model_key', inplace=True)\n",
    "    df.to_csv(csv_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(eval_results_dir, train_results_dir, dataset_dir, task, dataset_sufix=\"_original\", dataset_version=\"v1\", ds_name=\"\"):\n",
    "    \n",
    "    output_file_name = f\"eval_trained_on_dataset_{dataset_version}_task_{task}_ds_{ds_name}\"\n",
    "    \n",
    "    output_file = f\"logs/{output_file_name}.txt\"\n",
    "    csv_output_file = f'{eval_results_dir}/output_csvs/{output_file_name}.csv'\n",
    "    print(output_file)\n",
    "\n",
    "    evaluate_models(train_results_dir, output_file, dataset_dir, task, dataset_sufix, dataset_version)\n",
    "    process_file(os.path.join(eval_results_dir, output_file), csv_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [eval_results_dir, train_results_dir, dataset_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/flor/Desktop/git_repos/YOLO-OpenVINO-TVM-GStreamer/003-Evaluating-models',\n",
       " '/home/flor/Desktop/git_repos/YOLO-OpenVINO-TVM-GStreamer/003-Evaluating-models/../002-Training-models/train_results/chosen_models',\n",
       " '/home/flor/Desktop/git_repos/YOLO-OpenVINO-TVM-GStreamer/003-Evaluating-models/../datasets/']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing commands... DONE!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_evaluation(dirs[0], dirs[1], dirs[2], \"test\", dataset_sufix=\"_rc_no_empty\", dataset_version=\"v2\", ds_name=\"rc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
